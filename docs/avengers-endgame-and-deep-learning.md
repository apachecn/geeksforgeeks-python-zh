# å¤ä»‡è€…è”ç›Ÿæ¸¸æˆå’Œæ·±åº¦å­¦ä¹ |ä½¿ç”¨å¤ä»‡è€…è”ç›Ÿæ¸¸æˆè§’è‰²ç”Ÿæˆå›¾åƒæ ‡é¢˜

> åŸæ–‡:[https://www . geesforgeks . org/å¤ä»‡è€…è”ç›Ÿ-endgame-and-deep-learning/](https://www.geeksforgeeks.org/avengers-endgame-and-deep-learning/)

çœ‹ï¼Œæ¼«å¨çƒè¿·ã€‚å¤ä»‡è€…è”ç›Ÿåœ¨é‚£é‡Œæ‹¯æ•‘å¤šå…ƒå®‡å®™ï¼Œæˆ‘ä»¬ä¹Ÿæ˜¯ï¼Œå‡†å¤‡ä¸æƒœä¸€åˆ‡ä»£ä»·*æ”¯æŒä»–ä»¬*ã€‚
åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ·±åº¦å­¦ä¹ å’Œè®¡ç®—æœºè§†è§‰æ¥ç”Ÿæˆå¤ä»‡è€…è”ç›Ÿæ¸¸æˆè§’è‰²çš„å­—å¹•ã€‚æˆ‘ä»¬å°†ä»åŸºç¡€å¼€å§‹ï¼Œè§£é‡Šæ¦‚å¿µï¼Œå¹¶ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹æ¥å®æ–½é¡¹ç›®ã€‚

![](img/5108f1bb06509ed6caccab3df599d19f.png)

### æ¦‚è¿°:

å›¾åƒæ ‡é¢˜ç”Ÿæˆæ˜¯äººå·¥æ™ºèƒ½ä¸­ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œå®ƒå°†è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†è”ç³»åœ¨ä¸€èµ·ï¼Œå¿…é¡»ä¸ºç»™å®šçš„ç…§ç‰‡ç”Ÿæˆæ–‡æœ¬æè¿°ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå¯¹äºç»™å®šçš„å›¾åƒä½œä¸ºè¾“å…¥ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æè¿°äº†å›¾åƒçš„ç²¾ç¡®æè¿°ã€‚å®ƒæ—¢éœ€è¦å·ç§¯ç¥ç»ç½‘ç»œè¿™ä¸€è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å›¾åƒç†è§£ï¼Œåˆéœ€è¦è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„è¯­è¨€æ¨¡å‹ã€‚
å‡è®¾å¹¶æµ‹è¯•å¤šç§æ–¹æ³•æ¥æ¡†å®šç»™å®šçš„é¢„æµ‹å»ºæ¨¡é—®é¢˜æ˜¯å¾ˆé‡è¦çš„ï¼Œå¹¶ä¸”ç¡®å®æœ‰è®¸å¤šæ–¹æ³•æ¥æ¡†å®šä¸ºç…§ç‰‡ç”Ÿæˆæ ‡é¢˜çš„é—®é¢˜ã€‚æˆ‘ä»¬åšæŒä¸€ä¸ªæˆ‘ä»¬å°†åœ¨æœ¬æ–‡æœ«å°¾è§£é‡Šçš„è§‚ç‚¹ï¼Œæ‰€ä»¥åšæŒä¸€æ®µæ—¶é—´ã€‚ä½ èƒ½æ¡ä½**é›·ç¥é”¤å—ï¼ï¼ï¼**T3ã€ä¸ã€‘T4ï¼ï¼ä½†ä½ å¯ä»¥ç•™åœ¨è¿™é‡Œï¼Œå¼€ä¸ªç©ç¬‘ã€‚

å› æ­¤ï¼ŒåŸºæœ¬ä¸Šæˆ‘ä»¬çš„æ¨¡å‹æ‰€åšçš„æ˜¯ï¼Œå½“æˆ‘ä»¬å°†ä¸€å¹…å›¾åƒä¼ é€’ç»™æˆ‘ä»¬çš„ CNN å’Œ RNN ç»„åˆæ¶æ„æ—¶ï¼Œå®ƒå°†ä½¿ç”¨è‡ªç„¶è¯­è¨€å¤„ç†ç”Ÿæˆå›¾åƒçš„è‡ªç„¶æè¿°ã€‚

> æˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªåŸºäºæ·±åº¦é€’å½’ç¥ç»æ¶æ„çš„ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒä¸æœºå™¨ç¿»è¯‘ç›¸ç»“åˆï¼Œå¯ä»¥ç”¨æ¥ç”Ÿæˆæè¿°å›¾åƒçš„è‡ªç„¶å¥å­ã€‚è¯¥æ¨¡å‹è¢«è®­ç»ƒæ¥æœ€å¤§åŒ–ç»™å®šè®­ç»ƒå›¾åƒçš„ç›®æ ‡æè¿°å¥å­çš„å¯èƒ½æ€§ã€‚åœ¨å„ç§æ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºäº†æ¨¡å‹çš„å‡†ç¡®æ€§å’Œè¯­è¨€çš„æµç•…æ€§ï¼Œå®ƒä»…ä»å›¾åƒæè¿°ä¸­å­¦ä¹ ã€‚

**ä¾‹:**
![](img/6cb9b245b2a762a34cc6abdd5ee645c9.png)

åœ¨æ·±å…¥è®¨è®ºä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆäº†è§£ç†è§£è¯¥ç®—æ³•æ‰€éœ€çš„åŸºæœ¬æœ¯è¯­ã€‚

å®ƒä»¬åŸºæœ¬ä¸Šæ˜¯ä¸¤ç§ç±»å‹:

**åŸºäºå›¾åƒçš„æ¨¡å‹:**ä»å›¾åƒä¸­æå–ç‰¹å¾ã€‚
**åŸºäºè¯­è¨€çš„æ¨¡å‹:**å®ƒå°†æˆ‘ä»¬åŸºäºå›¾åƒçš„æ¨¡å‹ç»™å‡ºçš„ç‰¹å¾å’Œå¯¹è±¡ç¿»è¯‘æˆè‡ªç„¶çš„å¥å­ã€‚

å‹ç¼©ç‰¹å¾å‘é‡ç”±**å·ç§¯ç¥ç»ç½‘ç»œ**å½¢æˆã€‚ä¸€èˆ¬æ¥è¯´ï¼Œè¿™ä¸ªç‰¹å¾å‘é‡è¢«ç§°ä¸º ***åµŒå…¥*** ï¼Œè€Œ CNN æ¨¡å‹è¢«ç§°ä¸º ***ç¼–ç å™¨*** ï¼Œè¯¥ç¼–ç å™¨å¯¹ç»™å®šçš„ä¸€ç»„å­—è¿›è¡Œç¼–ç ï¼Œå¹¶ç”Ÿæˆä¼ é€’ç»™è§£ç å™¨ç½‘ç»œçš„åºåˆ—ã€‚åœ¨ä¸‹ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¿™äº›æ¥è‡ª CNN å±‚çš„åµŒå…¥ä½œä¸ºè¾“å…¥åˆ° ***LSTM ç½‘ç»œ*** ä¸­ï¼Œè¿™æ˜¯ä¸€ä¸ªè§£ç å™¨ï¼Œå®ƒå¯¹è¾“å…¥åºåˆ—è¿›è¡Œè§£ç å¹¶ç”Ÿæˆè¾“å‡ºã€‚

**ä¾‹å¦‚:**åƒæ³•è¯­åˆ°è‹±è¯­è¿™æ ·çš„è¯­è¨€ç¿»è¯‘ã€‚

åœ¨ä¸€ä¸ª**å¥å­è¯­è¨€æ¨¡å‹**ä¸­ï¼ŒLSTM æ­£åœ¨é¢„æµ‹ä¸€ä¸ªå¥å­ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯ã€‚ç»™å®šå›¾åƒçš„åˆå§‹åµŒå…¥ï¼Œè®­ç»ƒ LSTM æ¥é¢„æµ‹åºåˆ—çš„æœ€å¯èƒ½çš„ä¸‹ä¸€ä¸ªå€¼ã€‚è¿™å°±åƒç»™ä¸€ä¸ªäººçœ‹ä¸€å †å›¾åƒï¼Œè®©ä»–ä»¬è®°ä½å›¾åƒçš„ç»†èŠ‚ï¼Œç„¶åç»™ä»–ä»¬çœ‹ä¸€ä¸ªæ–°çš„å›¾åƒï¼Œè¿™ä¸ªå›¾åƒçš„å†…å®¹å’Œä¹‹å‰çš„å›¾åƒç›¸ä¼¼ï¼Œè®©ä»–ä»¬å›å¿†ä¸€ä¸‹å†…å®¹ã€‚è¿™ä¸ªâ€œå›å¿†â€å’Œâ€œè®°ä½â€çš„å·¥ä½œæ˜¯ç”±æˆ‘ä»¬çš„ LSTM ç½‘ç»œå®Œæˆçš„ï¼Œå®ƒåœ¨è¿™é‡Œè¦æœ‰ç”¨å¾—å¤šã€‚ç¨åå½“æˆ‘è°ˆåˆ°å®ç°éƒ¨åˆ†æ—¶ï¼Œæˆ‘å°†å‘æ‚¨å±•ç¤ºå®ƒå®é™…ä¸Šæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨åœ¨ ImageNet æ•°æ®é›†ä¸Šè®­ç»ƒçš„é¢„è®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œã€‚å›¾åƒè¢«è½¬æ¢ä¸ºæ ‡å‡†åˆ†è¾¨ç‡ **224 X 224 X 3** (nh x hw x nc)ï¼Œè¿™å°†ä½¿ä»»ä½•ç»™å®šå›¾åƒçš„æ¨¡å‹çš„è¾“å…¥æ’å®šã€‚

æŠ€æœ¯ä¸Šï¼Œæˆ‘ä»¬è¿˜æ’å…¥**å¼€å§‹**å’Œ**åœæ­¢**æ¥è¡¨ç¤ºå­—å¹•ç»“æŸã€‚

**ç¤ºä¾‹:**

![](img/c9083bc32f9bbd08d0fda1d0783c20e5.png)

> å¦‚æœå›¾åƒæè¿°ä¸º**â€œæ‰˜å°¼Â·æ–¯å¡”å…‹ä¸å¥‡å¼‚åšå£«ç«™åœ¨ä¸€èµ·â€**ï¼Œåˆ™æºåºåˆ—ä¸ºåŒ…å«**ã€ã€‘*(å¼€å§‹)*ã€ã€æ‰˜å°¼ã€‘ã€ã€æ–¯å¡”å…‹ã€‘ã€ã€æ˜¯ã€‘ã€ã€ç«™ç€ã€‘ã€ã€è·Ÿç€ã€‘ã€ã€åŒ»ç”Ÿã€‘ã€ã€å¥‡æ€ªã€‘**çš„åˆ—è¡¨ï¼Œç›®æ ‡åºåˆ—ä¸ºåŒ…å«**ã€ã€æ‰˜å°¼ã€‘ã€ã€æ–¯å¡”å…‹ã€‘ã€ã€æ˜¯ã€‘ã€ã€ç«™ç€ã€‘ã€ã€è·Ÿç€ã€‘ã€ã€åŒ»ç”Ÿã€‘ã€ã€å¥‡æ€ªã€‘ã€*(ç»“æŸ)*ã€‘**ã€‚ä½¿ç”¨è¿™äº›æºå’Œç›®æ ‡åºåˆ—ä»¥åŠç‰¹å¾å‘é‡ï¼Œ **LSTM è§£ç å™¨**è¢«è®­ç»ƒä¸ºä»¥ç‰¹å¾å‘é‡ä¸ºæ¡ä»¶çš„è¯­è¨€æ¨¡å‹ã€‚

ä¸‹å›¾æ›´å¥½åœ°è§£é‡Šäº†â€“

![](img/b94f10485fd746e1ec7d0c40d8e76973.png)

**æµ‹è¯•é˜¶æ®µ:**
åœ¨æµ‹è¯•é˜¶æ®µï¼Œ**ç¼–ç å™¨éƒ¨åˆ†**ä¸è®­ç»ƒé˜¶æ®µå‡ ä¹ç›¸åŒã€‚å”¯ä¸€ä¸åŒçš„æ˜¯ **[æ‰¹å¤„ç†å›¾å±‚](https://keras.io/layers/normalization/)** ä½¿ç”¨çš„æ˜¯æ–¹å·®å’Œå¹³å‡å€¼ï¼Œè€Œä¸æ˜¯å°æ‰¹é‡ç»Ÿè®¡ã€‚è¿™å¯ä»¥ä½¿ç”¨ **encoder.eval()** åŠŸèƒ½è½»æ¾å®ç°ã€‚å¯¹äº**è§£ç å™¨éƒ¨åˆ†**ï¼Œè®­ç»ƒé˜¶æ®µå’Œæµ‹è¯•é˜¶æ®µæœ‰ç€è‡³å…³é‡è¦çš„åŒºåˆ«ã€‚åœ¨æµ‹è¯•é˜¶æ®µï¼ŒLSTM è§£ç å™¨æ— æ³•è§‚å¯Ÿåˆ°å›¾åƒæè¿°ã€‚ä¸ºäº†å¤„ç†è¿™ç§æƒ…å†µï¼ŒLSTM è§£ç å™¨å°†å…ˆå‰ç”Ÿæˆçš„å­—åé¦ˆç»™ä¸‹ä¸€ä¸ªè¾“å…¥ã€‚è¿™å¯ä»¥ä½¿ç”¨ for å¾ªç¯æ¥å®ç°ã€‚

**åŸºæœ¬æœ‰ä¸¤ç§å­—å¹•ç”Ÿæˆæ¨¡å‹:**

### æ¨¡å‹ 1:

**ç”Ÿæˆæ•´ä¸ªåºåˆ—:**ç¬¬ä¸€ç§æ–¹æ³•åŒ…æ‹¬ä¸ºç»™å®šå›¾åƒçš„å¯¹è±¡ç”Ÿæˆæ•´ä¸ªæ–‡æœ¬æè¿°ã€‚

![](img/47e60d6f538267370c91c4546f29e777.png)

```
 Input: Photograph 
 Output: Complete textual description.

```

è¿™æ˜¯ä¸€ä¸ªä¸€å¯¹å¤šåºåˆ—é¢„æµ‹æ¨¡å‹ï¼Œä»¥ä¸€æ¬¡æ€§æ–¹å¼ç”Ÿæˆæ•´ä¸ªè¾“å‡ºã€‚

*   è¿™ç§æ¨¡å‹ç»™è¯­è¨€æ¨¡å‹å¸¦æ¥äº†æ²‰é‡çš„è´Ÿæ‹…ï¼Œè¦ä»¥æ­£ç¡®çš„é¡ºåºç”Ÿæˆæ­£ç¡®çš„å•è¯ã€‚
*   å›¾åƒé€šè¿‡ç‰¹å¾æå–æ¨¡å‹ï¼Œä¾‹å¦‚åœ¨å›¾åƒç½‘æ•°æ®é›†ä¸Šé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ã€‚
*   ä¸€ç§çƒ­ç¼–ç ç”¨äºè¾“å‡ºåºåˆ—ï¼Œè¿™å…è®¸æ¨¡å‹é¢„æµ‹åºåˆ—ä¸­æ¯ä¸ªå•è¯åœ¨æ•´ä¸ªè¯æ±‡è¡¨ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒã€‚
*   æ‰€æœ‰åºåˆ—éƒ½è¢«å¡«å……åˆ°ç›¸åŒçš„é•¿åº¦ï¼Œè¿™æ„å‘³ç€æ¨¡å‹è¢«è¿«åœ¨è¾“å‡ºåºåˆ—ä¸­ç”Ÿæˆå¤šä¸ªâ€œæ— è¯â€æ—¶é—´æ­¥é•¿ã€‚
*   æµ‹è¯•è¿™ç§æ–¹æ³•æ—¶ï¼Œæˆ‘ä»¬å‘ç°éœ€è¦ä¸€ä¸ªéå¸¸å¤§çš„è¯­è¨€æ¨¡å‹ï¼Œå³ä½¿è¿™æ ·ä¹Ÿå¾ˆéš¾é€šè¿‡ç”ŸæˆæŒä¹…æ€§çš„ NLP ç­‰ä»·ç‰©çš„æ¨¡å‹ï¼Œ**ç¤ºä¾‹:**ç”Ÿæˆæ•´ä¸ªåºåˆ—é•¿åº¦é‡å¤çš„ç›¸åŒå•è¯ä½œä¸ºè¾“å‡ºã€‚

### æ¨¡å‹ 2:

**ä»å•è¯ç”Ÿæˆå•è¯:**è¿™æ˜¯ä¸€ç§ä¸åŒçš„æ–¹æ³•ï¼Œå…¶ä¸­ LSTM ç»™å®šä¸€ä¸ªå›¾åƒå’Œä¸€ä¸ªå•è¯ä½œä¸ºè¾“å…¥ï¼Œç”Ÿæˆä¸€ä¸ªå•è¯çš„é¢„æµ‹ã€‚

![](img/c064370b349d4eb664444cda6bf85f91.png)

```
 Input 1: Image 
 Input 2: Previously generated word or start of sequence token. 
 Output:  Next word in sequence.

```

è¿™æ˜¯ä¸€ä¸ªä¸€å¯¹ä¸€çš„åºåˆ—é¢„æµ‹æ¨¡å‹ï¼Œå®ƒé€šè¿‡é€’å½’è°ƒç”¨æ¨¡å‹æ¥ç”Ÿæˆæ–‡æœ¬æè¿°ã€‚

*   ä¸€ä¸ªå•è¯è¾“å…¥æˆ–è€…æ˜¯åœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ¨¡å‹çš„æƒ…å†µä¸‹æŒ‡ç¤ºåºåˆ—å¼€å§‹çš„æ ‡è®°ï¼Œæˆ–è€…æ˜¯ä»ä¸Šä¸€æ¬¡è°ƒç”¨æ¨¡å‹æ—¶ç”Ÿæˆçš„å•è¯ã€‚
*   å›¾åƒé€šè¿‡ä¸€ä¸ªç‰¹å¾æå–æ¨¡å‹ï¼Œå°±åƒåœ¨ ImageNet æ•°æ®é›†ä¸Šé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ä¸€æ ·ï¼Œè¾“å…¥çš„å•è¯é€šè¿‡å•è¯åµŒå…¥è¿›è¡Œæ•´æ•°ç¼–ç ã€‚
*   è¾“å‡ºå•è¯æ˜¯ä¸€ç§çƒ­ç¼–ç ï¼Œå®ƒå…è®¸æ¨¡å‹é¢„æµ‹æ•´ä¸ªè¯æ±‡ä¸­å•è¯çš„æ¦‚ç‡ã€‚
*   é€’å½’å•è¯ç”Ÿæˆè¿‡ç¨‹ä¸æ–­é‡å¤ï¼Œç›´åˆ°ç”Ÿæˆåºåˆ—ç»“æŸæ ‡è®°ã€‚
*   é€šè¿‡æµ‹è¯•è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬å‘ç°æ¨¡å‹ç¡®å®ç”Ÿæˆäº†ä¸€äº›å¥½çš„ n-gram åºåˆ—ï¼Œä½†æ˜¯é™·å…¥äº†ä¸€ä¸ªå¾ªç¯ä¸­ï¼Œå¯¹äºé•¿æè¿°é‡å¤ç›¸åŒçš„å•è¯åºåˆ—ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€é”€ï¼Œå› ä¸ºæ¨¡å‹å†…å­˜ä¸è¶³ï¼Œæ— æ³•è®°ä½ä¹‹å‰ç”Ÿæˆçš„å†…å®¹ã€‚

**è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå›¾åƒå­—å¹•çš„ä¾‹å­æ¥è·å¾—æ›´æ·±å±‚æ¬¡çš„ç›´è§‰ã€‚**

> **ä¸ºäº†å¼€å‘ä¸€ä¸ªå›¾åƒå­—å¹•æ¨¡å‹ï¼Œæˆ‘ä»¬å°†å…¶åˆ†è§£ä¸ºä¸‰ä¸ªéƒ¨åˆ†:**
> 
> 1)æå–è¦åœ¨æ¨¡å‹ä¸­ä½¿ç”¨çš„å›¾åƒç‰¹å¾ã€‚
> 2)åœ¨æˆ‘ä»¬ä»å›¾åƒä¸­æå–çš„é‚£äº›ç‰¹å¾ä¸Šè®­ç»ƒæ¨¡å‹ã€‚
> 3)å½“æˆ‘ä»¬å°†è¾“å…¥å›¾åƒçš„ç‰¹å¾ä¼ é€’ç»™ç½‘ç»œæ—¶ï¼Œä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆå­—å¹•æ–‡æœ¬ã€‚

**æˆ‘ä»¬æœ‰ä¸¤ç§ä¸åŒçš„æŠ€æœ¯æ¥åšåˆ°è¿™ä¸€ç‚¹â€“**

**1ã€‚**ç”¨äºå›¾åƒç‰¹å¾æå–çš„è§†è§‰å‡ ä½•ç¾¤ç¥ç»ç½‘ç»œ(VGG)ã€‚
T3ã€‘2ã€‚é€’å½’ç¥ç»ç½‘ç»œ(RNN)ï¼Œç”¨äºé€šè¿‡æ¨¡å‹è®­ç»ƒå’Œç”Ÿæˆå­—å¹•æ–‡æœ¬ã€‚

**æ­¥éª¤#1:**
ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„ VGG æ¨¡å‹ï¼Œå›¾åƒè¢«è¯»å…¥å¹¶è°ƒæ•´å¤§å°ä¸º 224*224*3ï¼Œè¯¥å›¾åƒå…·æœ‰ä¸‰ä¸ªé¢œè‰²é€šé“ï¼Œç„¶åè¢«é¦ˆé€åˆ° VGG ç¥ç»ç½‘ç»œï¼Œåœ¨é‚£é‡Œç‰¹å¾è¢«æå–ä¸º Numpy é˜µåˆ—ã€‚ç”±äºè¿™é‡Œä½¿ç”¨ VGG ç½‘ç»œæ¥è¿›è¡Œå›¾åƒåˆ†ç±»ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸æ˜¯ä»æœ€åä¸€å±‚è·å¾—è¾“å‡ºï¼Œè€Œæ˜¯ä»åŒ…å«å›¾åƒç‰¹å¾æ•°æ®çš„å…¨è¿æ¥(FC-2)å±‚è·å¾—è¾“å‡ºã€‚

**æ­¥éª¤#2:**
å¯¹äºå­—å¹•å›¾åƒï¼Œä½¿ç”¨ Kerasï¼Œåˆ›å»ºä¸€ä¸ªå…·æœ‰ 256 ä¸ªç¥ç»å…ƒçš„å•ä¸ª LSTM(é•¿æœŸçŸ­æœŸè®°å¿†)ç»†èƒã€‚å¯¹äºè¿™ä¸ªå•å…ƒï¼Œæˆ‘ä»¬æœ‰å››ä¸ªè¾“å…¥:**å›¾åƒç‰¹å¾ã€å­—å¹•ã€é®ç½©å’Œå½“å‰ä½ç½®**é¦–å…ˆå­—å¹•è¾“å…¥å’Œä½ç½®è¾“å…¥è¢«è¿æ¥(åˆå¹¶)ï¼Œç„¶åå®ƒé€šè¿‡ä¸€ä¸ªå•è¯**åµŒå…¥å±‚**ï¼Œç„¶åå›¾åƒç‰¹å¾å’ŒåµŒå…¥çš„å•è¯ä¹Ÿä¸é®ç½©è¾“å…¥è¢«åˆå¹¶(ä½¿ç”¨è¿æ¥)ã€‚å®ƒä»¬ä¸€èµ·é€šè¿‡ LSTM å•å…ƒï¼Œç„¶å LSTM å•å…ƒçš„è¾“å‡ºé€šè¿‡ Dropout å’Œ Batch Normalization å±‚ï¼Œä»¥é˜²æ­¢æ¨¡å‹ **[è¿‡åº¦æ‹Ÿåˆ](https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/)** ã€‚æœ€åï¼Œåº”ç”¨è½¯æœ€å¤§éçº¿æ€§ï¼Œå¾—åˆ°äº†é¢„æœŸçš„ç»“æœã€‚

[![](img/2240948dcf7b35d9a1c80dc78bc4e0fe.png)](https://media.geeksforgeeks.org/wp-content/uploads/20190422135728/Untitled-Diagram-41-2.jpg)

æˆ‘ä»¬å¾—åˆ°çš„ç»“æœæ˜¯ä¸€ä¸ªå‘é‡ï¼Œæ¯ä¸ªæ¡ç›®ä»£è¡¨å­—å…¸ä¸­æ¯ä¸ªå•è¯çš„å¯èƒ½æ€§ã€‚æœ€æœ‰å¯èƒ½çš„å•è¯å°†æ˜¯æˆ‘ä»¬å½“å‰çš„â€œæœ€ä½³å•è¯â€ã€‚è¿åŒé¢„å…ˆæ„å»ºçš„å­—å…¸ï¼Œè¿™ä¸ªå‘é‡è¢«ç”¨æ¥â€œè§£é‡Šâ€ä¸‹ä¸€ä¸ªç”Ÿæˆçš„å•è¯ï¼Œè¯¥å•è¯å¯ä»¥è¢«è®¤ä¸ºæ˜¯ä¸€ç§ç”¨äºè®­ç»ƒçœŸå®å­—å¹•çš„åŸºæœ¬äº‹å®ã€‚æ©ç åœ¨è¿™ä¸€åˆ‡ä¸­èµ·ç€é‡è¦çš„ä½œç”¨ï¼Œâ€œè®°å½•â€å­—å¹•ä¸­ä½¿ç”¨çš„å‰ä¸€ä¸ªå•è¯ï¼Œä»¥ä¾¿æ¨¡å‹çŸ¥é“å½“å‰å•è¯ä¹‹å‰çš„å•è¯ï¼Œå¹¶ç”¨å¥å­çš„å½“å‰ä½ç½®è¾“å…¥æ¨¡å‹ï¼Œè¿™æ ·å®ƒå°±ä¸ä¼šé™·å…¥å¾ªç¯ã€‚

![](img/c06a938a9feb2a8848d6f84bee88d3f4.png)

ç±»ä¼¼äºè®­ç»ƒï¼Œæˆ‘ä»¬è¿˜éœ€è¦è·å–æ¯ä¸ªå¾…é¢„æµ‹å›¾åƒçš„ç‰¹å¾ã€‚å› æ­¤ï¼Œå›¾åƒé¦–å…ˆç»è¿‡ VGG-16 ç½‘ç»œæ¶æ„ï¼Œä»¥ç”Ÿæˆç‰¹å¾ã€‚å¯¹äºå­—å¹•ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ç›¸åŒçš„ LSTM æ¨¡å¼ã€‚è¿™ä¸ªæ¨¡å‹çš„ç¬¬ä¸€ä¸ªå•è¯è¾“å…¥æ˜¯â€œ#start#â€æ ‡è®°ï¼Œåé¢çš„è¾“å…¥æ˜¯å‰ä¸€æ¬¡è¿­ä»£çš„é¢„æµ‹ç»“æœã€‚

**æ¨¡å‹æ¶æ„:**

![](img/dddcc9a25a5351375b60efe63cb908e4.png)

æˆ‘ä»¬é¼“åŠ±æ‚¨çœ‹ä¸€çœ‹è¿™ç¯‡[ç ”ç©¶è®ºæ–‡](https://arxiv.org/abs/1411.4555)ï¼Œä»¥è·å¾—å…³äºåˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆçš„æ¸…æ™°ç›´è§‰ã€‚

å­˜å‚¨å—åŒ…å«ç”±ä¸‰ä¸ªé—¨æ§åˆ¶çš„å•å…ƒâ€œCâ€ã€‚åœ¨è“è‰²ä¸­ï¼Œæˆ‘ä»¬æ˜¾ç¤ºäº†åå¤å‡ºç°çš„è¿æ¥ï¼Œæ—¶é—´â€œt-1â€çš„è¾“å‡ºâ€œmâ€é€šè¿‡ä¸‰ä¸ªé—¨åé¦ˆåˆ°æ—¶é—´â€œtâ€çš„å­˜å‚¨å™¨ï¼Œå•å…ƒå€¼é€šè¿‡å¿˜è®°é—¨åé¦ˆï¼Œæ—¶é—´â€œt-1â€çš„é¢„æµ‹å­—é™¤äº†æ—¶é—´â€œtâ€çš„å­˜å‚¨å™¨è¾“å‡ºâ€œmâ€ä¹‹å¤–ï¼Œè¿˜åé¦ˆåˆ°ç”¨äºå­—é¢„æµ‹çš„ Softmax å‡½æ•°ã€‚è¯»å–å…¶è¾“å…¥é—¨â€œIâ€ä»¥åŠæ˜¯å¦è¾“å‡ºæ–°çš„å•å…ƒå€¼(è¾“å‡ºé—¨ o)ã€‚

![](img/a7664ddccd88c6b61f5bd74ff390cef1.png)

*   **ç¼–ç å™¨-è§£ç å™¨æ¶æ„:**é€šå¸¸ï¼Œç”Ÿæˆåºåˆ—çš„æ¨¡å‹å°†ä½¿ç”¨ç¼–ç å™¨å°†è¾“å…¥ç¼–ç ä¸ºå›ºå®šå½¢å¼ï¼Œä½¿ç”¨è§£ç å™¨å°†å…¶é€å­—è§£ç ä¸ºåºåˆ—ã€‚
*   **æ³¨æ„åŠ›:**æ³¨æ„åŠ›ç½‘ç»œçš„ä½¿ç”¨åœ¨æ·±åº¦å­¦ä¹ ä¸­å¹¿æ³›å­˜åœ¨ï¼Œå¹¶ä¸”ç†ç”±å……åˆ†ã€‚è¿™æ˜¯ä¸€ç§æ¨¡å‹åªé€‰æ‹©å®ƒè®¤ä¸ºä¸æ‰‹å¤´ä»»åŠ¡ç›¸å…³çš„ç¼–ç éƒ¨åˆ†çš„æ–¹æ³•ã€‚æ‚¨åœ¨è¿™é‡Œçœ‹åˆ°çš„ç›¸åŒæœºåˆ¶å¯ä»¥ç”¨äºä»»ä½•æ¨¡å‹ï¼Œå…¶ä¸­ç¼–ç å™¨çš„è¾“å‡ºåœ¨ç©ºé—´æˆ–æ—¶é—´ä¸Šæœ‰å¤šä¸ªç‚¹ã€‚åœ¨å›¾åƒå­—å¹•ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºæŸäº›åƒç´ æ¯”å…¶ä»–åƒç´ æ›´é‡è¦ã€‚ä¸ºäº†ç»™æœºå™¨ç¿»è¯‘è¿™æ ·çš„ä»»åŠ¡æ’åºï¼Œä½ ä¼šè€ƒè™‘ä¸€äº›è¯æ¯”å…¶ä»–è¯æ›´é‡è¦ã€‚
*   **Transfer Learning:** å°±æ˜¯å½“ä½ é€šè¿‡åœ¨æ–°æ¨¡å‹ä¸­ä½¿ç”¨ç°æœ‰æ¨¡å‹çš„ä¸€éƒ¨åˆ†æ¥å€Ÿç”¨å®ƒæ—¶ï¼Œè¿™å‡ ä¹æ€»æ˜¯æ¯”ä»å¤´å¼€å§‹è®­ç»ƒä¸€ä¸ªæ–°æ¨¡å‹æ›´å¥½(å³ä¸€æ— æ‰€çŸ¥)æ­£å¦‚ä½ å°†çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬æ€»æ˜¯å¯ä»¥å°†è¿™äº›äºŒæ‰‹çŸ¥è¯†å¾®è°ƒåˆ°æ‰‹å¤´çš„ç‰¹å®šä»»åŠ¡ï¼Œä½¿ç”¨é¢„å…ˆè®­ç»ƒå¥½çš„å•è¯åµŒå…¥æ˜¯ä¸€ä¸ªæ— æ•ˆä½†æœ‰æ•ˆçš„ä¾‹å­ã€‚æˆ‘ä»¬å°†ä½¿ç”¨é¢„è®­ç»ƒçš„ç¼–ç å™¨ï¼Œç„¶åæ ¹æ®éœ€è¦å¯¹å…¶è¿›è¡Œå¾®è°ƒã€‚
*   **Beam Search:** æ˜¯æˆ‘ä»¬ä¸è®©æ‚¨çš„ Decoder å·æ‡’çš„åœ°æ–¹ï¼Œåªéœ€åœ¨æ¯ä¸ªè§£ç æ­¥éª¤ä¸­é€‰æ‹©å¾—åˆ†æœ€é«˜çš„å•è¯ï¼ŒBeam Search å¯¹äºä»»ä½•è¯­è¨€å»ºæ¨¡é—®é¢˜éƒ½å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºå®ƒå¯ä»¥æ‰¾åˆ°æœ€ä½³åºåˆ—ã€‚

### è®©æˆ‘ä»¬é€šè¿‡ä»£ç æ¥ç†è§£:

### å…ˆå†³æ¡ä»¶-

```
Anaconda
Pytorch
MSCOCO Dataset    

```

è¦å¤åˆ¶æœ¬æ–‡çš„ç»“æœï¼Œè¯·ç¡®ä¿å®‰è£…äº†å…ˆå†³æ¡ä»¶ã€‚ç°åœ¨è®©æˆ‘ä»¬ä»å¤´å¼€å§‹è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼ŒæŒ‰ç…§ä¸‹é¢çš„æ­¥éª¤ã€‚

**æ•°æ®é›†**

```
git clone https://github.com/pdollar/coco.git
cd coco/PythonAPI/
make
python setup.py build
python setup.py install
cd ../../
git clone https://github.com/yunjey/pytorch-tutorial.git
cd pytorch-tutorial/tutorials/03-advanced/image_captioning/
pip install -r requirements.txt 

```

**æ³¨æ„:**æˆ‘ä»¬å»ºè®®ä½ ä½¿ç”¨è°·æ­Œ[T3ã€ColabT5](https://colab.research.google.com/drive/1VjGl0OJsZbcGiwy9u1NQoAr-YhgzNHu2#scrollTo=RDf1X0EfBYED) 

**é¢„è®­ç»ƒæ¨¡å‹â€“**
æˆ‘ä»¬å…ˆä» **[è¿™é‡Œ](https://drive.google.com/drive/folders/1SrJZm3Teg1IOC1ZIbr0tQLkLir0skwnx?usp=sharing)** ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹å’Œè¯æ±‡æ–‡ä»¶ï¼Œç„¶åæŠŠ**é¢„è®­ç»ƒ _model.zip** è§£å‹åˆ°**ã€‚/è½¦å‹/** å’Œ **vocab.pkl** è‡³**ã€‚/data/** ä½¿ç”¨è§£å‹ç¼©å‘½ä»¤ã€‚

**ç°åœ¨æ¨¡å‹å‡†å¤‡å¥½äº†ï¼Œå¯ä»¥ä½¿ç”¨**æ¥é¢„æµ‹å­—å¹•

```
$ python sample.py --image='/example.png'
```

### è®©æˆ‘ä»¬å¼€å§‹è¡¨æ¼”å§ï¼

å¯¼å…¥æ‰€æœ‰åº“ï¼Œå¹¶ç¡®ä¿ç¬”è®°æœ¬ä½äºå­˜å‚¨åº“çš„æ ¹æ–‡ä»¶å¤¹ä¸­:

```
import torch
import matplotlib.pyplot as plt
import numpy as npÂ 
import argparse
import pickleÂ 
import os
from torchvision import transformsÂ 
from PIL import Image

# this file is located in pytorch tutorial/imageÂ 
# captioning which we pull from git remember
from build_vocab import VocabularyÂ Â Â 
from model import EncoderCNN, DecoderRNN
```

**ç¡¬ç¼–ç æ¨¡å‹ä¸èƒ½ä¿®æ”¹:**

```
# Model pathÂ 

# make sure path must correctÂ 
ENCODER_PATH = 'content/encoder-5-3000.pkl'Â 
DECODER_PATH = 'content/decoder-5-3000.pkl'
VOCAB_PATH =Â Â  'content/vocab.pkl'

# CONSTANTS because of architecture what we are using
EMBED_SIZE = 256
HIDDEN_SIZE = 512
NUM_LAYERS = 1
```

**è¦åŠ è½½ _imageï¼Œæ·»åŠ æ­¤é…ç½®ä»£ç :**

```
# Device configuration snippet
device = torch.cuda.device(0) # 0 represent default device

# Function to Load and Resize the image
def load_image(image_path, transform=None):Â 
Â Â image = Image.open(image_path)
Â Â image = image.resize([224, 224], Image.LANCZOS)
Â Â if transform is not None:
Â Â Â Â image = transform(image).unsqueeze(0)
Â Â return image
```

**ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç¼–å†™ä¸€ä¸ª PyTorch å‡½æ•°ï¼Œå®ƒä½¿ç”¨é¢„å¤„ç†çš„æ•°æ®æ–‡ä»¶æ¥é¢„æµ‹è¾“å‡º:**

```
def PretrainedResNet(image_path, encoder_path=ENCODER_PATH,Â 
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â decoder_path=DECODER_PATH,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â vocab_path=VOCAB_PATH,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â embed_size=EMBED_SIZE,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â hidden_size=HIDDEN_SIZE,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â num_layers=NUM_LAYERS):

Â Â Â Â # Image preprocessing
Â Â Â Â transform = transforms.Compose([
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â transforms.ToTensor(),Â 
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â transforms.Normalize((0.485, 0.456, 0.406),Â 
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â (0.229, 0.224, 0.225))])

Â Â Â Â # Load vocabulary wrapper
Â Â Â Â with open(vocab_path, 'rb') as f:
Â Â Â Â Â Â Â Â vocab = pickle.load(f)

Â Â Â Â # Build models

Â Â Â Â # eval mode (batchnorm uses moving mean/variance)
Â Â Â Â encoder = EncoderCNN(embed_size).eval()Â Â 
Â Â Â Â decoder = DecoderRNN(embed_size, hidden_size,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â len(vocab), num_layers)

Â Â Â Â encoder = encoder.to(device)
Â Â Â Â decoder = decoder.to(device)

Â Â Â Â # Load the trained model parameters
Â Â Â Â encoder.load_state_dict(torch.load(encoder_path))
Â Â Â Â decoder.load_state_dict(torch.load(decoder_path))

Â Â Â Â # Prepare an image
Â Â Â Â image = load_image(image_path, transform)
Â Â Â Â image_tensor = image.to(device)

Â Â Â Â # Generate a caption from the image
Â Â Â Â feature = encoder(image_tensor)
Â Â Â Â sampled_ids = decoder.sample(feature)

Â Â Â Â # (1, max_seq_length) -> (max_seq_length)
Â Â Â Â sampled_ids = sampled_ids[0].cpu().numpy()Â Â Â Â Â Â Â Â Â 

Â Â Â Â # Convert word_ids to words
Â Â Â Â sampled_caption = []
Â Â Â Â for word_id in sampled_ids:
Â Â Â Â Â Â Â Â word = vocab.idx2word[word_id]
Â Â Â Â Â Â Â Â sampled_caption.append(word)
Â Â Â Â Â Â Â Â if word == '<end>':
Â Â Â Â Â Â Â Â Â Â Â Â break
Â Â Â Â sentence = ' '.join(sampled_caption)[8:-5].title()Â 

Â Â Â Â # Print out the image and the generated caption
Â Â Â Â image = Image.open(image_path)
Â Â Â Â return sentence, image
```

è®©æˆ‘ä»¬ä»ã€Šå¤ä»‡è€…è”ç›Ÿã€‹çš„ä¸€äº›åœºæ™¯å¼€å§‹åˆ¶ä½œå­—å¹•ï¼Œçœ‹çœ‹å®ƒæ¦‚æ‹¬å¾—æœ‰å¤šå¥½ï¼Œåˆ«å¿˜äº†æ¬£èµã€‚

**ä½¿ç”¨ä»¥ä¸‹ä»£ç é¢„æµ‹æ ‡ç­¾:**

```
plt.figure(figsize=(24,24))
predicted_label, image = PretrainedResNet(image_path='IMAGE_PATH')
plt.imshow(image)
print(predicted_label)
```

### æˆ‘ä»¬æœ‰ç»¿å·¨äººï¼Œç°åœ¨æˆ‘ä»¬æœ‰æ·±åº¦å­¦ä¹ ã€‚ğŸ˜€

**æµ‹è¯•å›¾åƒ:é›·ç¥æ ‡è®° I**

*æˆ‘ä»¬æ¥çœ‹çœ‹è¿™ä¸ªå½¢è±¡*
![](img/bebb43364d569e0998ffa198440e92cc.png)
*ç°åœ¨ä½ æ€ä¹ˆçœ‹è¿™ä¸ªå½¢è±¡ï¼Ÿåœ¨è„‘æµ·ä¸­ä¿ç•™ä¸€ä¸ªæ ‡é¢˜ï¼Œä¸è¦å‘ä¸‹æ»šåŠ¨ã€‚*

```
plt.figure(figsize=(17,19))
predicted_label, img = PretrainedResNet(image_path='./image/AVENGERENDGAME1.png')
plt.imshow(img)
print(predicted_label)
```

**è¾“å‡º:**
![](img/4015a14bcb633c6b2202403517507d96.png)

```
Thor 
```

**æµ‹è¯•å›¾ç‰‡:æ‰˜å°¼-é©¬å…‹ 2 å·**
![](img/fbcbab3e802b0a036bdff61a6d1794d2.png)

*ç°åœ¨ä½ æ€ä¹ˆçœ‹è¿™å¼ å›¾ç‰‡ï¼Ÿåœ¨è„‘æµ·ä¸­ä¿ç•™ä¸€ä¸ªæ ‡é¢˜ï¼Œä¸è¦å‘ä¸‹æ»šåŠ¨ã€‚*

```
plt.figure(figsize=(22,22))
predicted_label, img = PretrainedResNet(image_path='./image/AVENGERENDGAME2.png')
plt.imshow(img)
print(predicted_label)
```

**è¾“å‡º:**
![](img/22fe56325ade2888db6708301950c860.png)

```
(tony and doctor strange)
```

**æµ‹è¯•å›¾åƒ:ç»¿å·¨äºº-é©¬å…‹ä¸‰ä¸–**
![](img/3dc27c712b64eea92aaf6e99d13dae5e.png)

*ç°åœ¨ä½ æ€ä¹ˆçœ‹è¿™å¼ å›¾ç‰‡ï¼Ÿåœ¨è„‘æµ·ä¸­ä¿ç•™ä¸€ä¸ªæ ‡é¢˜ï¼Œä¸è¦å‘ä¸‹æ»šåŠ¨ã€‚*

```
plt.figure(figsize=(42,49))
predicted_label, img = PretrainedResNet(image_path='./image/AVENGERENDGAME3.png')
plt.imshow(img)
print(predicted_label)
```

**è¾“å‡º:**
![](img/43e9147b8f37818c3a59c48323fda76a.png)

```
(thanos and Hulk)
```

**æ³¨æ„:**æˆ‘ä»¬è¿™é‡Œä½¿ç”¨çš„æ˜¯å›¾ç‰‡åç§°`AVENGERENDGAME*.png`ï¼Œå…¶ä¸­*ä» 1ï¼Œ2ï¼Œ3 â€¦ç­‰å˜åŒ–ï¼Œä½†æ˜¯ä½ å¯ä»¥æ”¾è‡ªå·±çš„å›¾ç‰‡ï¼Œè®°ä½ä¸€ä¸ªå¯èƒ½ä¼šå¾—åˆ°ä¸åŒçš„æ ‡é¢˜ï¼Œå¦ä¸€ä¸ªå¯èƒ½ä¼šå¾—åˆ°ä¸åŒçš„æ ‡é¢˜ã€‚